{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1vyY1JLF/HBRht8q5fPj4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdeepbanerjee-git/Cost_Sensitive_Learning/blob/main/MA4_cost_sens_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will take the wine quality [dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv) and build the baseline classification model. We will convert the continuous y variable (\"quality\") into three segements:\n",
        "- \"Good\" (>= 7)\n",
        "- \"Average\" (> 5)\n",
        "- \"Poor\" (<= 5)"
      ],
      "metadata": {
        "id": "kICpsKiujFii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "wine_data = pd.read_csv(url, sep=';')\n",
        "\n",
        "# Define quality thresholds\n",
        "def quality_label(quality):\n",
        "    if quality >= 7:\n",
        "        return 'Good'\n",
        "    elif quality > 5:\n",
        "        return 'Average'\n",
        "    else:\n",
        "        return 'Poor'\n",
        "\n",
        "# Apply the thresholds to create a new target column\n",
        "wine_data['quality_label'] = wine_data['quality'].apply(quality_label)"
      ],
      "metadata": {
        "id": "xWxNMyXHi8zD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we drop the previous continuous target variable, consider the newly generated 'quality_label' as y and split into train and test data\n",
        "# Separate features and target\n",
        "X = wine_data.drop(columns=['quality', 'quality_label'])\n",
        "y = wine_data['quality_label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y) # stratified random sampling"
      ],
      "metadata": {
        "id": "I7iyqlrji8wR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see the class distribution of the 4 labels and compare before and after the split\n",
        "print(y.value_counts(normalize = True).round(2),\n",
        "      y_train.value_counts(normalize =  True).round(2),\n",
        "      y_test.value_counts(normalize = True).round(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV8ik6f5i8tk",
        "outputId": "d6265b5c-d992-4134-9450-227610d473a7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quality_label\n",
            "Poor       0.47\n",
            "Average    0.40\n",
            "Good       0.14\n",
            "Name: proportion, dtype: float64 quality_label\n",
            "Poor       0.47\n",
            "Average    0.40\n",
            "Good       0.14\n",
            "Name: proportion, dtype: float64 quality_label\n",
            "Poor       0.46\n",
            "Average    0.40\n",
            "Good       0.14\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the class thresholds are chosen in such a way that it becomes an imbalanced dataset, which is closer to a real-world situation. Also, it prepares the ground for the use case where cost-sensitive learning will come into play.\n",
        "\n",
        "We also find that the same distribution is present in the test data. We will be using the scikit-learn pipeline to build the models so that the preprocessing and modeling steps can be applied sequentially with ease."
      ],
      "metadata": {
        "id": "8VzvIEvrl0b3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature scaling and encoding\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Initialize the scaler and encoder\n",
        "scaler = StandardScaler()\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Encode the target labels\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test) # we won't need this as we will inverse transform the predicted labels\n",
        "\n",
        "# Create a pipeline for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', scaler, X.columns)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "xoqpLI94i8qi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline and model\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Instantiate a Random Forest Classifier model\n",
        "model = RandomForestClassifier(n_estimators=100,\n",
        "                               random_state=42)\n",
        "\n",
        "# Combine preprocessing and model into a pipeline\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', model)])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Decode the predictions to original labels\n",
        "y_pred_labels = encoder.inverse_transform(y_pred)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_labels))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkzyrXmMi8nr",
        "outputId": "735aff75-ed90-4807-99a1-b4fd14263c77"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[124  13  55]\n",
            " [ 28  32   5]\n",
            " [ 40   3 180]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Average       0.65      0.65      0.65       192\n",
            "        Good       0.67      0.49      0.57        65\n",
            "        Poor       0.75      0.81      0.78       223\n",
            "\n",
            "    accuracy                           0.70       480\n",
            "   macro avg       0.69      0.65      0.66       480\n",
            "weighted avg       0.70      0.70      0.70       480\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining a cost matrix and calculating real-world cost of misclassification:\n",
        "I will define and calculate costs in terms of Euros and wine production and consumption both are very high there.\n",
        "\n",
        "We will consider the following:\n",
        "- the average wine costs 5 euros/bottle.\n",
        "- A good wine if predicted as average costs 10 Euros loss, but if predicted as Poor should cost higher, say 20 Euros/bottle loss.\n",
        "- Similarly if a Poor wine predicted as Good the cost is high but a little less than 20, say 15 (since it is an indirect loss to the company in terms of brand may be)\n",
        "\n",
        "Note: these are just assumptions or guesstimates to show you the methodology and give a feel of the problem - the real-world cost matrix may be different.\n"
      ],
      "metadata": {
        "id": "F45t47WLrj78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Cost matrix: cost[i][j] represents the cost of predicting class j when the true class is i\n",
        "cost_matrix = np.array([[0, 10, 20],\n",
        "                        [8, 0, 5],\n",
        "                        [15, 7, 0]])"
      ],
      "metadata": {
        "id": "bKg3CqF7rjkw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the cost matrix we will now calculate the cost of misclassification\n",
        "\n",
        "# Cost-sensitive evaluation\n",
        "def calculate_total_cost(y_true, y_pred, cost_matrix):\n",
        "    total_cost = 0\n",
        "    # jsut summing up costs of misclassification for all our predictions\n",
        "    for true, pred in zip(y_true, y_pred):\n",
        "        total_cost += cost_matrix[true, pred] # cost[i][j]\n",
        "    return total_cost\n",
        "\n",
        "# Calculate the total cost of the cost-sensitive predictions\n",
        "total_cost = calculate_total_cost(y_test_encoded, y_pred, cost_matrix)\n",
        "print(f'Total Misclassification Cost: {total_cost}')\n",
        "\n",
        "average_cost = total_cost/len(y_test)\n",
        "print(f'Average Misclassification Cost per prediction: {average_cost.round(2)} Euros/bottle')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCNUTsWwrjfM",
        "outputId": "d786a983-0c08-4f49-9674-a0fa85edc5d0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Misclassification Cost: 2156\n",
            "Average Misclassification Cost per prediction: 4.49 Euros/bottle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, with the baseline model, the average cost of misclassification per prediction or per bottle is 4.5 Euros, which is pretty high, given that my average wine costs 5 Euros.\n",
        "\n",
        "To reslove this issue, we will make use of cost-sensitive learning. We will generate class weights based on its misclassification cost and pass it to the model so that it optimizes the loss accordingly."
      ],
      "metadata": {
        "id": "-AiGCIsGvwqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate raw class weights by summing costs for each class\n",
        "raw_class_weights = cost_matrix.sum(axis=1) # sum of each row as row is true label\n",
        "print(\"Raw class weights:\", raw_class_weights)\n",
        "\n",
        "# Normalize by sum of weights\n",
        "norm_class_weights = raw_class_weights / raw_class_weights.sum()\n",
        "print(\"Normalized class weights by sum:\", norm_class_weights) # order is Good, Average and Poor.\n",
        "\n",
        "# We now convert the class weights Convert to dictionary format expected by scikit-learn\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(norm_class_weights)}\n",
        "print(\"Class weights dictionary:\", class_weights_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ngC1_i9rjQK",
        "outputId": "52e735ec-8410-4243-91d6-e449a0e79a21"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw class weights: [30 13 22]\n",
            "Normalized class weights by sum: [0.46153846 0.2        0.33846154]\n",
            "Class weights dictionary: {0: 0.46153846153846156, 1: 0.2, 2: 0.3384615384615385}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The sum of the class weights is 1.\n",
        "\n",
        "Now, we will retrain the model with these weights."
      ],
      "metadata": {
        "id": "TyEYbd7YxpaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with these class weights\n",
        "model = RandomForestClassifier(n_estimators=100,\n",
        "                               class_weight=class_weights_dict,\n",
        "                               random_state=123)\n",
        "\n",
        "# Combine preprocessing and model into a pipeline\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', model)])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Decode the predictions to original labels\n",
        "y_pred_labels = encoder.inverse_transform(y_pred)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_labels))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFYbNLF7rjK9",
        "outputId": "9ea93bbe-1feb-4f4e-a472-1585e044094f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[125  14  53]\n",
            " [ 29  30   6]\n",
            " [ 32   3 188]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Average       0.67      0.65      0.66       192\n",
            "        Good       0.64      0.46      0.54        65\n",
            "        Poor       0.76      0.84      0.80       223\n",
            "\n",
            "    accuracy                           0.71       480\n",
            "   macro avg       0.69      0.65      0.67       480\n",
            "weighted avg       0.71      0.71      0.71       480\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, there is an increase in f1-score for the label Good resulting in 1% increase in overall accuracy. But in each case the precision and recalls have changed too. Let's see how it affects the overall cost."
      ],
      "metadata": {
        "id": "KBo5Hpm5y27l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total cost of the cost-sensitive predictions\n",
        "total_cost = calculate_total_cost(y_test_encoded, y_pred, cost_matrix)\n",
        "print(f'Total Misclassification Cost: {total_cost}')\n",
        "\n",
        "average_cost = total_cost/len(y_test)\n",
        "print(f'Average Misclassification Cost per prediction: {average_cost.round(2)} Euros/bottle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8-FRamUi8ie",
        "outputId": "0214a309-e30e-49fe-a1c2-9fd46c3efe04"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Misclassification Cost: 1963\n",
            "Average Misclassification Cost per prediction: 4.09 Euros/bottle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! The overall and average cost reduced by ~ 9% with the help of cost-sensitive learning!\n"
      ],
      "metadata": {
        "id": "vwBoJL-zz2S-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KlXCGO1-0X13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uaT3pS460XsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M2r584vr0RS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WmhV3Hsu0RIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pA7C8Ohm0Q-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tHPNYt2g0Q0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gd2xNhXwi8gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nps9nWd6i8dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-c-rhDXxi8ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhphMkfGi7-O"
      },
      "outputs": [],
      "source": []
    }
  ]
}